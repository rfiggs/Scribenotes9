\documentclass[11pt]{article}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}

\newcommand{\handout}[5]{
  \noindent
  \begin{center}
  \framebox{
    \vbox{
      \hbox to 5.78in { {\bf ICS 443: Parallel Algorithms} \hfill #2 }
      \vspace{4mm}
      \hbox to 5.78in { {\Large \hfill #5  \hfill} }
      \vspace{2mm}
      \hbox to 5.78in { {\em #3 \hfill #4} }
    }
  }
  \end{center}
  \vspace*{4mm}
}

\newcommand{\lecture}[4]{\handout{#1}{#2}{#3}{Scribe: #4}{Lecture #1}}

\newtheorem{theorem}{Theorem}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{observation}[theorem]{Observation}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{assumption}[theorem]{Assumption}

% 1-inch margins, from fullpage.sty by H.Partl, Version 2, Dec. 15, 1988.
\topmargin 0pt
\advance \topmargin by -\headheight
\advance \topmargin by -\headsep
\textheight 8.9in
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.5in

\parindent 0in
\parskip 1.5ex
%\renewcommand{\baselinestretch}{1.25}

\begin{document}

\lecture{9 --- September 25, 2017}{Fall 2017}{Prof.\ Nodari Sitchinava}{Isaac DeMello, Brandon Doan, Robert Figgs}

\section{Overview}

In the last lecture we detailed an algorithm that finds the minimum of an array in O$(\log_2(\log_2(n)))$ time, and with O$(n(\log_2(\log_2(n)))$ work.

In this lecture we define a work-efficient algorithm that finds the minimum in O$(\log_2(\log_2(n)))$ and with O$(n)$ work. We also begin to look at searching algorithms.  \ldots.

\section{Work Efficient Min}

We begin by breaking down the algorithm into parts of size k, where k = O$(\log_2(\log_2(n)))$
\subsection{WE-CRCW-min}
In order to break down the size of the array and apply the previously defined CRCW-min algorithm covered in lecture 9. We use the following algorithm:

\begin{algorithm}
\caption{WE-CRCW-min$(A,n)$}
\begin{algorithmic}
\STATE k = $\lceil\log_2(\log_2(n))\rceil$
\STATE n' = $\lceil n/k \rceil$
\STATE B = new array of size n'
\FOR {$i=1$ to $n'$ in parallel}
	\STATE {B[i]=A[(i-1)k+1]}
	\FOR {$j = (i-1)k+2$ to $ik$ in parallel}
    \STATE $B[i] = min(B[i], A[j])$
	\ENDFOR
\ENDFOR
\RETURN CRCW-min(B, 1, n')
\end{algorithmic}
\end{algorithm}


\subsubsection{WE-CRCW-min Algorithmic Analysis}
The first 3 lines of the algorithm can be done in constant time, this means that the runtime of the algorithm is dominated by the for-loop.



\paragraph{Work Analysis}: Work of this algorithm can be shown as follows:


$\sum_{i=1}^{n} \sum_{j=(i-1)k+2}^{ik}O(1)$ =
$\theta(n'*k)$ =
$\theta((n/k) * k)$ = $\theta(n)$

\section{Searching}

We start with a trivial parallel searching algorithm. Note that this algorithm assumes that every element in the array is distinct. This algorithm will also return a value of -1 if the element is not found in the array.

\begin{algorithm}
\caption{parallel-search$(A,n,x)$}
\begin{algorithmic}
\STATE answer = -1
\FOR {$i=1$ to $n$ in parallel}
	\IF{A[i] == x}
	    \STATE answer = i
	\ENDIF
\ENDFOR
\RETURN answer
\end{algorithmic}
\end{algorithm}

We can see that because this all runs in parallel, our run time is $T_\infty(n) = O(1)$ and our work is $W(n) = O(n)$

If we plug these values into Brent's scheduling principle we get
$T_P(n) = O(\frac{n}{p}+1)$ This isn't a fantastic run time so lets see if we can make this any better. We'll start by reviewing the sequential algorithms for Binary Search, and Binary Search Trees. Note that these two algorithms assume that the input is sorted.

\subsection{Binary Search}
Binary search is a sequential algorithm. It can only be used on a pre-sorted array. This algorithm returns the index of the of the element if it is found between the left and right indices . Otherwise it will return -1.
\pagebreak


\begin{algorithm}
\caption{Binary-Search$(A,l,r,x)$}
\begin{algorithmic}
\IF{$r < l$}
    \RETURN -1
\ELSE
    \STATE mid = $\lfloor\frac{l+r}{2}\rfloor$
    \IF{$A[mid] == x$}
        \RETURN mid
    \ELSIF{$x < A[mid]$}
        \RETURN Binary-Search($A,l,mid-1,x$)
    \ELSE
        \RETURN Binary-Search($A,mid+1,r,x$)
    \ENDIF
\ENDIF
\end{algorithmic}
\end{algorithm}

The run time for this algorithm is $T(n) = T(\frac{n}{2}) + O(1)$. Using master theorem we get $T(n) = O(\log n)$


\subsection{Binary Search Tree}
A binary search tree is a special type of binary tree. The only difference is that in binary search tree, the children on the left of the node all are less than the value of the node, and the children on the right side of the node are all greater than the node. To search through the Binary Search Tree we can use the following sequential algorithm. Note that this algorithm returns nil if the element is not found.

\begin{algorithm}
\caption{BST-Search$(root,x)$}
\begin{algorithmic}
\IF{$root == nil$ or $root.key == x$}
    \RETURN root
\ELSIF{$x < root.key$}
    \RETURN BST-Search($root.left,x$)
\ELSE
    \RETURN BST-Search($root.right,x$)
\ENDIF
\end{algorithmic}
\end{algorithm}

The run-time of this algorithm depends on how well balanced the binary search tree was before running this algorithm.

\section{Parallel Search w/ parallel predecessor algorithm}
In the previous parallel searching algorithm, if the element being searched for was not in the array, it would return a -1 value. Instead for our purposes, we can utilize a predecessor algorithm to provide us with the index of the largest element $\leq$ x, in the case where x was not found within the array. This will provide useful later on when implementing a work-efficient parallel version of the Mergesort algorithm.

We also went over how a binary search works with an array as well as a binary tree. One benefit of having multiple processors is the ability to increase the size of the tree. For example we are able to store more entries and children nodes based upon the amount of processors at our disposal. For p amount of processors we have p amount of entries per node, and p + 1 children.

\subsection{Parallel Predecessor}
 The following algorithm is a sequential algorithm that is used to find the predecessor within a sorted array.

\begin{algorithm}
\caption{par-predecessor$(A,x)$}
\begin{algorithmic}
\STATE answer = 0
\FOR {$i=1$ to $n$ in parallel}
	\IF{A[i] = x}
    	\RETURN i
	\ELSIF{A[i] $<$ x $\&\&$ (A[i = 1] $>$ x $\&\&$ i $<$ n)}
    	\STATE answer = i
	\ENDIF
	\IF{A[n] $<$ x}
    	\STATE answer = n
	\ENDIF
	\RETURN answer
\ENDFOR
\end{algorithmic}
\end{algorithm}

The runtime for par-predecessor is $T(n) = O(1)$, as the algorithm checks all n elements at the same time in parallel and all the operations within are constant.
Using the same logic, the work for par-predecessor will be. $$\sum_{i=1}^{n}O(1)$$
$W(n) = O(n)$

If we were to use a multi branch search tree algorithm similar to the binary search tree algorithm, we would be able to find the predecessor in $\log_p n$ runtime. Where p is the amount of processors.


\subsection{Revised Parallel Search}

Now we can implement our revised parallel search on a multi-branched tree with multiple entries per node, while using a par-predecessor algorithm. Before starting we can specify some of the properties of the tree. The node object shall contain a key and child such that, V.key[i] will be the index of a specific entry in a particular node and v.child[i] will be a pointer to a child of the node. The following algorithm takes three arguments, V the node, p the amount of processors, and x the element being searched for. A reminder that the size of key is equal to p, and child is p + 1 in size.

\begin{algorithm}
\caption{Parallel-Search w/predecessor(Node V, p, x)}
\begin{algorithmic}
\IF{V == nil}
	\RETURN "Not Found"
\ENDIF
\STATE $child\_idx = par-predecessor(V.key, p, x)$
\IF{$(child\_idx \quad > \quad 0 \quad \&\& \quad V.key[child\_idx] == x)$}
	\RETURN (V.key[child\_idx])
\ELSE
	\RETURN Parallel-Search(V.child[child\_idx], p, x)
\ENDIF
\end{algorithmic}
\end{algorithm}

The run-time of this algorithm, like the binary search tree depends on how well balanced it was before running the algorithm. In the case of a balanced tree, the height is $O(\log_p n)$ therefore, the runtime will be  $T(n) = O(\log_p n)$ 


%\bibliography{mybib}
\bibliographystyle{alpha}

\end{document}
